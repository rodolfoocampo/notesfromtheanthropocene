How can indigenous knowledge enhance AI design?
how can we design Ai that is compatible with indigenous worldviews?

This is a collection of papers and their notes on the topic. 



**[How can indigenous knowledge shape our view of AI](https://policyoptions.irpp.org/magazines/february-2018/how-can-indigenous-knowledge-shape-our-view-of-ai/)**, article by Karina Kesserwan

- Seven generation concept. People should act thinking 7 generations down the line. How do design decisions change is we take that view?
- Indigenous ontologies view everything as having a soul. Would AI have a soul?
- *Australian anthropologist Genevieve Bell [recently underlined the cultural context of AI systems](https://www.youtube.com/watch?v=WBHG4eBeMXk) when she ruminated about whether a particular AI was Christian, or perhaps Buddhist, or Lutheran, depending on how it was envisioned to operate. The AI systems we develop certainly have our world views embedded in them. Integrating Indigenous perspectives would allow us to build a different kind of AI.*



[Enhancing Artificial Intelligence with Indigenous Wisdom, Academic Paper
](https://www.scirp.org/journal/paperinformation.aspx?paperid=106983)
- For example, the Navajo concept of _hozho_ involves the normative values and goals of harmony, balance, interrelatedness, and connectedness. _Hozho_ and other Indigenous concepts are potentially paradigm-shifting additions to artificial wisdom and could greatly enhance the usefulness of and overall benefit from applications of artificial intelligence. This is related to [[Indigenous relational ontologies]].

This paragraph from the paper pretty much sums up the whole thing. 
- *The AI systems we develop certainly have our worldviews embedded in them. Integrating Indigenous perspectives would allow us to build a different kind of AI” (Kesserwan, 2018). For example, Bourgeois-Doyle (2019) proposed a “Two-Eyed AI” concept for guiding the development and application of AI based on the Two-Eyed Seeing principle of seeing through one eye with the best of the Indigenous way of knowing and through the other eye with the best of Western science. Maitra (2020) discussed the value of Indigenous perspectives in addressing concerns about potential negative impacts of powerful AI on human civilization, and proposed incorporating Indigenous relational ethics into AI programming in order to instill a more human-friendly foundation and thereby mitigate or avoid these negative impacts. As discussed, value alignment attempts to ensure that AI is encoded with human values in its infancy, and Indigenous ontologies, especially relational dynamics, should be considered as an extension of value alignment (Maitra, 2020). For example, as long as humans maintain a scheme in which they are superior beings using AI as means to their own ends there is a risk that AI may invert this hierarchy, so to empower and protect humans from AI, we should include AI in our “circle of relationships” and thereby create a reciprocal relationship between AI and humans (Maitra, 2020, citing Liu & Zawieska, 2017).*



**Making kin with the machines**

-I referenced this article in a standalone note. It centers around the concept on how to [[make kin with the machines]].

- It also references [[Genevieve Bell]] and her idea of labelling AI to understand what is is. For example, by labeling it as indigenous AI, and asking what that means. 




